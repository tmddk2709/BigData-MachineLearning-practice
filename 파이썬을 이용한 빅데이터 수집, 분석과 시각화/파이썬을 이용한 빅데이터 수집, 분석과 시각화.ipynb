{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6장 트위터 데이터 수집하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cache-control': 'no-cache, no-store, max-age=0', 'content-length': '62', 'content-type': 'application/json; charset=utf-8', 'date': 'Thu, 06 Aug 2020 15:24:28 GMT', 'server': 'tsa_m', 'set-cookie': 'personalization_id=\"v1_HW6+h5rHgEYV4icgD4nAyA==\"; Max-Age=63072000; Expires=Sat, 6 Aug 2022 15:24:28 GMT; Path=/; Domain=.twitter.com; Secure; SameSite=None, guest_id=v1%3A159672746823789998; Max-Age=63072000; Expires=Sat, 6 Aug 2022 15:24:28 GMT; Path=/; Domain=.twitter.com; Secure; SameSite=None', 'strict-transport-security': 'max-age=631138519', 'x-connection-hash': '6f4d0c27d9841415dc53b059852966e4', 'x-response-time': '103', 'status': '400', '-content-encoding': 'gzip'}\n",
      "400\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-388959d34b8f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 112\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-35-388959d34b8f>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[0mtweets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_user_timeline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mtweet\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtweets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m         \u001b[0mgetTwitterTwit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtweet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjsonResult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "import oauth2\n",
    "import json\n",
    "import datetime\n",
    "import time\n",
    "from config import *\n",
    "\n",
    "def oauth2_request(consumer_key, consumer_secret, access_token, access_secret):\n",
    "    try:\n",
    "        consumer = oauth2.Consumer(key=consumer_key, secret=consumer_secret)\n",
    "        token = oauth2.Token(key=access_token, secret=access_secret)\n",
    "        client = oauth2.Client(consumer, token)\n",
    "        return client\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None\n",
    "    \n",
    "    \n",
    "def get_user_timeline(client, screen_name, count=50, include_rts='False'):\n",
    "    base = \"https://api.twitter.com/1.1\"\n",
    "    node = \"/statuses/user_timeline.json\"\n",
    "    fields = \"?screen_name=%s&count=%s&include_rts=%s\" % (screen_name, count, include_rts)\n",
    "    #fields = \"?screen_name=%s\" % (screen_name)\n",
    "    url = base + node + fields\n",
    "    \n",
    "    response, data = client.request(url)\n",
    "    \n",
    "    try:\n",
    "        if response['status'] == '200':\n",
    "            return json.loads(data.decode('utf-8'))\n",
    "        else:\n",
    "            print(response)\n",
    "            print(response['status'])\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None\n",
    "    \n",
    "    \n",
    "def getTwitterTwit(tweet, jsonResult):\n",
    "    tweet_id = tweet['id_str']\n",
    "    tweet_message = '' if 'text' not in tweet.keys() else tweet['text']\n",
    "    screen_name = '' if 'user' not in tweent.keys() else tweet['user']['screen_name']\n",
    "    tweet_link = ''\n",
    "    \n",
    "    if tweet['entities']['urls']:\n",
    "        for i, val in enumerate(tweet['entitles']['urls']):\n",
    "            tweet_link = tweet_link + tweet['entities']['urls'][i]['url'] + ''\n",
    "    else:\n",
    "        tweet_link = ''\n",
    "    \n",
    "    hashtags = ''\n",
    "    if tweet['entities']['hashtags']:\n",
    "        for i, val in enumerate(tweet['entities']['hashtags']):\n",
    "            hashtags = hasgtags + tweet['entities']['hashtags'][i]['text'] + ''\n",
    "    else:\n",
    "        hashtags = ''\n",
    "        \n",
    "    if 'created_at' in tweet.keys():\n",
    "        tweet_published = datetime.datetime.strptime(tweet['created_at'], '%a %b %d %H:%M:%S +0000 %Y)')\n",
    "        tweet_published = tweet_published + datetime.timedelta(hours=+9)\n",
    "        tweet_published = tweet_published.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    else:\n",
    "        tweet_published = ''\n",
    "        \n",
    "    num_favorite_count = 0 if 'favorite_count' not in tweet.keys() else tweet['favorite_count']\n",
    "    num_comments = 0\n",
    "    num_shares = 0 if 'retweet_count' not in tweet.keys() else tweet['retweet_count']\n",
    "    num_likes = num_favorite_count\n",
    "    num_loves = num_wows = num_hahas = num_sads = num_angrys = 0\n",
    "    \n",
    "    jsonResult.append({'post_id':tweet_id,\n",
    "                      'message':tweet_message,\n",
    "                      'name':screen_name,\n",
    "                      'link':tweet_link,\n",
    "                      'created_time':tweet_published,\n",
    "                      'num_reactions':num_favorite_count,\n",
    "                      'num_comments':num_comments,\n",
    "                      'num_shares':num_shares,\n",
    "                      'num_likes':num_likes,\n",
    "                      'num_loves':num_loves,\n",
    "                      'num_wows':num_wows,\n",
    "                      'num_hahas':num_hahas,\n",
    "                      'num_sads':num_sads,\n",
    "                      'num_angrys':num_angrys,\n",
    "                      'hashtags':hashtags})\n",
    "    \n",
    "    \n",
    "def main():\n",
    "    screen_name = 'T1_LOL'\n",
    "    num_posts = 50\n",
    "    jsonResult = []\n",
    "    \n",
    "    CONSUMER_KEY = 'ZIzHfI8x13sTyyvestefxDXU8'\n",
    "    CONSUMER_SECRET = 'exOG5JS9myqdeZQ3fU2GA2mFOfuu3sGQOQuXZpaYp133D3NynR'\n",
    "    ACCESS_TOKEN = '1246285995357552640-PNs1cCbgYNI4WRVtC1zkBghZuavrkU0'\n",
    "    ACCESS_SECRET = 'ePOQQvsitkfhwKpRVN1HjcMhM3KaH9Kri3uzzivLbgeJv'\n",
    "    \n",
    "    client = oauth2_request(CONSUMER_KEY, CONSUMER_SECRET, ACCESS_TOKEN, ACCESS_SECRET)\n",
    "    tweets = get_user_timeline(client, screen_name)\n",
    "    \n",
    "    for tweet in tweets:\n",
    "        getTwitterTwit(tweet, jsonResult)\n",
    "        \n",
    "    with open('%s_twitter.json' % (screen_name), 'w', encoding='utf-8') as outfile:\n",
    "        str_ = json.dumps(jsonResult,\n",
    "                         indent=4,\n",
    "                         sort_keys=True,\n",
    "                         ensure_ascii=False)\n",
    "        print('%s_twitter.json SAVED' % (screen_name))\n",
    "        \n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7장 네이버 데이터 수집하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1 검색 API의 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-08-06 07:59:37.216871] Url Request Success for URL: https://openapi.naver.com/v1/search/news.json?query=T1&start=1&display=100\n",
      "[2020-08-06 07:59:37.421332] Url Request Success for URL: https://openapi.naver.com/v1/search/news.json?query=T1&start=101&display=100\n",
      "[2020-08-06 07:59:37.618633] Url Request Success for URL: https://openapi.naver.com/v1/search/news.json?query=T1&start=201&display=100\n",
      "[2020-08-06 07:59:37.839750] Url Request Success for URL: https://openapi.naver.com/v1/search/news.json?query=T1&start=301&display=100\n",
      "[2020-08-06 07:59:38.090727] Url Request Success for URL: https://openapi.naver.com/v1/search/news.json?query=T1&start=401&display=100\n",
      "[2020-08-06 07:59:38.322713] Url Request Success for URL: https://openapi.naver.com/v1/search/news.json?query=T1&start=501&display=100\n",
      "[2020-08-06 07:59:38.538778] Url Request Success for URL: https://openapi.naver.com/v1/search/news.json?query=T1&start=601&display=100\n",
      "[2020-08-06 07:59:38.748003] Url Request Success for URL: https://openapi.naver.com/v1/search/news.json?query=T1&start=701&display=100\n",
      "[2020-08-06 07:59:38.971225] Url Request Success for URL: https://openapi.naver.com/v1/search/news.json?query=T1&start=801&display=100\n",
      "[2020-08-06 07:59:39.237135] Url Request Success for URL: https://openapi.naver.com/v1/search/news.json?query=T1&start=901&display=100\n",
      "HTTP Error 400: Bad Request\n",
      "[2020-08-06 07:59:39.348867] Error for URL: https://openapi.naver.com/v1/search/news.json?query=T1&start=1001&display=100\n",
      "T1_naver_news.json SAVED\n"
     ]
    }
   ],
   "source": [
    "# 비로그인 방식을 통한 네이버 뉴스, 블로그, 까페 글 검색\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import urllib.request\n",
    "import datetime\n",
    "import time\n",
    "import json\n",
    "from config import *\n",
    "\n",
    "def get_request_url(url):\n",
    "    \n",
    "    # urllib.request.Request는 class(abstraction of a URL request)\n",
    "    req = urllib.request.Request(url)\n",
    "    req.add_header(\"X-Naver-Client-Id\", \"iqwsSNAxP1UnkVXEd75A\")\n",
    "    req.add_header(\"X-Naver-Client-Secret\", \"eOK_0IHNOx\")\n",
    "    \n",
    "    try:\n",
    "        response = urllib.request.urlopen(req)\n",
    "        if response.getcode() == 200:\n",
    "            print(\"[%s] Url Request Success for URL: %s\" % (datetime.datetime.now(), url))\n",
    "            return response.read().decode('utf-8')\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(\"[%s] Error for URL: %s\" % (datetime.datetime.now(), url))\n",
    "        return None\n",
    "    \n",
    "def getNaverSearchResult(sNode, search_text, page_start, display):\n",
    "    \n",
    "    base = \"https://openapi.naver.com/v1/search\"\n",
    "    node = \"/%s.json\" % sNode\n",
    "    parameters = \"?query=%s&start=%s&display=%s\" % (urllib.parse.quote(search_text), page_start, display)\n",
    "    url = base + node + parameters\n",
    "    \n",
    "    retData = get_request_url(url)\n",
    "    \n",
    "    if (retData == None):\n",
    "        return None\n",
    "    else:\n",
    "        return json.loads(retData)\n",
    "    \n",
    "def getPostData(post, jsonResult):\n",
    "    \n",
    "    title = post['title']\n",
    "    description = post['description']\n",
    "    org_link = post['originallink']\n",
    "    link = post['link']\n",
    "    \n",
    "    pDate = datetime.datetime.strptime(post['pubDate'], '%a, %d %b %Y %H:%M:%S +0900')\n",
    "    pDate = pDate.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    \n",
    "    jsonResult.append({'title':title, \n",
    "                       'description':description,\n",
    "                       'org_link':org_link, \n",
    "                       'link':org_link,\n",
    "                       'pDate':pDate})\n",
    "    return\n",
    "    \n",
    "def main():\n",
    "    \n",
    "    jsonResult = []\n",
    "    \n",
    "    sNode = 'news' #'news', 'blog', 'cafearticle'\n",
    "    search_text = 'T1'\n",
    "    display_count = 100\n",
    "    \n",
    "    jsonSearch = getNaverSearchResult(sNode, search_text, 1, display_count)\n",
    "    \n",
    "    while((jsonSearch != None) and (jsonSearch['display'] != 0)):\n",
    "        for post in jsonSearch['items']:\n",
    "            getPostData(post, jsonResult)\n",
    "            \n",
    "        nStart = jsonSearch['start'] + jsonSearch['display']\n",
    "        jsonSearch = getNaverSearchResult(sNode, search_text, nStart, display_count)\n",
    "        \n",
    "    with open('%s_naver_%s.json' % (search_text, sNode), 'w', encoding='utf-8') as outfile:\n",
    "        retJson = json.dumps(jsonResult,\n",
    "                            indent=4,\n",
    "                            sort_keys=True,\n",
    "                            ensure_ascii=False)\n",
    "        outfile.write(retJson)\n",
    "        \n",
    "    print('%s_naver_%s.json SAVED' % (search_text, sNode))\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2 지도 API의 활용 - 카카오\n",
    "\n",
    "(네이버는 서비스 중단)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-08-06 09:40:00.258526] Url Request Success for URL: https://dapi.kakao.com/v2/local/search/keyword.json?query=T1\n",
      "총 검색 결과:  48\n",
      "검색어:  t1\n",
      "===========================\n",
      "주소:  서울 강남구 선릉로 627\n",
      "위도:  37.5124177833897\n",
      "경도:  127.042836395143\n",
      "===========================\n",
      "주소:  인천 중구 공항로 271\n",
      "위도:  37.4463799212184\n",
      "경도:  126.456718819439\n",
      "===========================\n",
      "주소:  인천 중구 공항로 271\n",
      "위도:  37.4480932459114\n",
      "경도:  126.457027378139\n",
      "===========================\n",
      "주소:  인천 중구 공항로 271\n",
      "위도:  37.4447868498249\n",
      "경도:  126.453570715701\n",
      "===========================\n",
      "주소:  서울 광진구 광나루로56길 85\n",
      "위도:  37.5357010612649\n",
      "경도:  127.095764656407\n",
      "===========================\n",
      "주소:  인천 중구 공항로 271\n",
      "위도:  37.4467374233447\n",
      "경도:  126.455305893658\n",
      "===========================\n",
      "주소:  인천 중구 공항로 271\n",
      "위도:  37.4452621939524\n",
      "경도:  126.452708414339\n",
      "===========================\n",
      "주소:  충남 서산시 안견로 254-5\n",
      "위도:  36.7780529696401\n",
      "경도:  126.454997829694\n",
      "===========================\n",
      "주소:  인천 중구 공항로 271\n",
      "위도:  37.4442803040782\n",
      "경도:  126.457050413717\n",
      "===========================\n",
      "주소:  인천 중구 공항로 271\n",
      "위도:  37.448056278615\n",
      "경도:  126.451557959658\n",
      "===========================\n",
      "주소:  인천 중구 공항로 271\n",
      "위도:  37.4417364131733\n",
      "경도:  126.452480973879\n",
      "===========================\n",
      "주소:  인천 중구 공항로 272\n",
      "위도:  37.4439789566915\n",
      "경도:  126.452663519696\n",
      "===========================\n",
      "주소:  인천 중구 공항로 271\n",
      "위도:  37.4454656563107\n",
      "경도:  126.453841513812\n",
      "===========================\n",
      "주소:  경기 포천시 영북면 산정호수로322번길 20\n",
      "위도:  38.0689496017404\n",
      "경도:  127.305234416028\n",
      "===========================\n",
      "주소:  \n",
      "위도:  37.4437297277891\n",
      "경도:  126.45410274001\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import urllib.request\n",
    "import datetime\n",
    "import time\n",
    "import json\n",
    "from config import *\n",
    "\n",
    "native_app_key = '1d9651c42f3d6f438e7afdfe7d9a1ff0'\n",
    "rest_api_key = '0d58fd941b80009d0ecb936b3787587a'\n",
    "javascript_key = '6a5981bdfce0fbdb71c6b49b4595fdaa'\n",
    "admin_key = '51838b22a226337ddea0b0285ddc202c'\n",
    "\n",
    "\n",
    "def get_request_url(url):\n",
    "    \n",
    "    req = urllib.request.Request(url)\n",
    "    req.add_header(\"Authorization\", \"KakaoAK \"+rest_api_key)\n",
    "    \n",
    "    try:\n",
    "        response = urllib.request.urlopen(req)\n",
    "        if response.getcode() == 200:\n",
    "            print(\"[%s] Url Request Success for URL: %s\" % (datetime.datetime.now(), url))\n",
    "            return response.read().decode('utf-8')\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(\"[%s] Error for URL: %s\" % (datetime.datetime.now(), url))\n",
    "        return None\n",
    "    \n",
    "\n",
    "def getGeoData(address):\n",
    "    \n",
    "    url = 'https://dapi.kakao.com/v2/local/search/keyword.json?query={}'.format(address)\n",
    "    \n",
    "    retData = get_request_url(url)\n",
    "    \n",
    "    if retData == None:\n",
    "        return None\n",
    "    else:\n",
    "        return json.loads(retData)\n",
    "    \n",
    "    \n",
    "def main():\n",
    "    \n",
    "    searching = 'T1'\n",
    "    jsonResult = getGeoData(searching)\n",
    "    \n",
    "    if 'meta' in jsonResult.keys():\n",
    "        print('총 검색 결과: ', jsonResult['meta']['total_count'])\n",
    "        print('검색어: ', jsonResult['meta']['same_name']['keyword'])\n",
    "        \n",
    "        for item in jsonResult['documents']:\n",
    "            print('===========================')\n",
    "            print('주소: ', item['road_address_name'])\n",
    "            print('위도: ', item['y'])\n",
    "            print('경도: ', item['x'])\n",
    "            \n",
    "            \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9장 일반적인 웹 서비스 데이터 수집하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.1 이상한 나라의 앨리스의 맛있는 스프: BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "강철비2: 정상회담\n",
      "다만 악에서 구하소서\n",
      "반도\n",
      "#살아있다\n",
      "존 윅\n",
      "소년시절의 너\n",
      "알라딘\n",
      "오케이 마담\n",
      "세인트 주디\n",
      "1942: 언노운 배틀\n",
      "빅샤크3: 젤리몬스터 대소동\n",
      "밤쉘: 세상을 바꾼 폭탄선언\n",
      "강철비\n",
      "온워드: 단 하루의 기적\n",
      "블랙아웃 : 인베이젼 어스\n",
      "프리즈너\n",
      "키싱 부스 2\n",
      "테넷\n",
      "봉오동 전투\n",
      "정도\n",
      "애니멀 크래커\n",
      "팬데믹\n",
      "국제수사\n",
      "승리호\n",
      "고스트 오브 워\n",
      "위대한 쇼맨\n",
      "마티아스와 막심\n",
      "팡파레\n",
      "반교: 디텐션\n",
      "블루 아워\n",
      "카오산 탱고\n",
      "기기괴괴 성형수\n",
      "결백\n",
      "큐리오사\n",
      "인베이젼 2020\n",
      "양자물리학\n",
      "올드 가드\n",
      "모든 것을 벗어던진 특별한 여행\n",
      "파리의 인어\n",
      "소년 아메드\n",
      "극장판 짱구는 못말려: 신혼여행 허리케인~ 사라진 아빠!\n",
      "키싱 부스\n",
      "소셜노마드\n",
      "워터 릴리스\n",
      "가버나움\n",
      "디바\n",
      "기담\n",
      "사라진 시간\n",
      "킹스맨: 퍼스트 에이전트\n",
      "루비\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "html = urllib.request.urlopen('https://movie.naver.com/movie/sdb/rank/rmovie.nhn')\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "tags = soup.findAll('div', attrs={'class':'tit3'})\n",
    "for tag in tags:\n",
    "    print(tag.a.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12장 지리정보기반 시각화: 지리정보와 시각화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.2 포리움(Folium)의 설치 및 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "map_osm = folium.Map(location=[37.566345, 126.977893])\n",
    "map_osm.save('./map1.html')\n",
    "map_osm = folium.Map(location=[37.566345, 126.977893], zoom_start=17)\n",
    "map_osm.save('./map2.html')\n",
    "map_osm = folium.Map(location=[37.566345, 126.977893], zoom_start=17, tiles='Stamen Terrain')\n",
    "map_osm.save('./map3.html')\n",
    "map_osm = folium.Map(location=[37.566345, 126.977893], zoom_start=17, tiles='Stamen Toner')\n",
    "map_osm.save('./map4.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

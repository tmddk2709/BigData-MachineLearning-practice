{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow \n",
    "import gym"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"FrozenLake-v0\")\n",
    "observation = env.reset()\n",
    "\n",
    "for _ in range(1000):\n",
    "    env.render()\n",
    "    action = env.action_space.sample() #your agent here(this takes random actions)\n",
    "    observation, reward, done, info = env.step(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### python arrow keyin\n",
    "\n",
    "class _Getch:\n",
    "    def __call__(self):\n",
    "        fd = sys.stdin.fileno()\n",
    "        old_settings = termios.tcgetattr(fd)\n",
    "        try:\n",
    "            tty.setraw(sys.stdin.fileno())\n",
    "            ch = sys.stdin.read(3)\n",
    "        finally:\n",
    "            termios.tcsetattr(fd, termios.TCSADRAIN, old_settings)\n",
    "            \n",
    "        return ch\n",
    "    \n",
    "inkey = _Getch()\n",
    "\n",
    "#MACROS\n",
    "LEFT  = 0\n",
    "DOWN  = 1\n",
    "RIGHT = 2\n",
    "UP    = 3\n",
    "\n",
    "#Key mapping\n",
    "arrow_keys = {\n",
    "    '\\x1b[A' : UP,\n",
    "    '\\x1b[B' : DOWN,\n",
    "    '\\x1b[C' : RIGHT,\n",
    "    '\\x1b[D' : LEFT\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym.envs.registration import register\n",
    "import sys, tty, termios\n",
    "\n",
    "#Register FrozenLake with is_sleppery False\n",
    "register(id='FrozenLake-v3', entry_point='gym.envs.toy_text:FrozenLakeEnv', kwargs={'map_name':'4x4', 'is_slippery':False})\n",
    "\n",
    "env = gym.make('FrozenLake-v3')\n",
    "env.render() #Show the initial board\n",
    "\n",
    "while True:\n",
    "    #Choose an action from keyboard\n",
    "    key = inkey()\n",
    "    if key not in arrow_keys.keys():\n",
    "        print(\"Game aborted!\")\n",
    "        break\n",
    "        \n",
    "    action = arrow_keys[key]\n",
    "    state, reward, done, info = env.step(action)\n",
    "    env.render() #Show the board after action\n",
    "    print(\"State :\", state, \"Action :\", action, \"Reward :\", reward, \"info :\", info)\n",
    "    \n",
    "    if done:\n",
    "        print(\"Finished with reward\", reward)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success rate : 0.53\n",
      "Final Q-Table values\n",
      "LEFT DOWN RIGHT UP\n",
      "[[0. 1. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 0. 0.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from gym.envs.registration import register\n",
    "import random as pr\n",
    "\n",
    "def rargmax(vector):\n",
    "    \"\"\"Argmax that chooses randomly among eligible maximum indices.\"\"\"\n",
    "    m = np.amax(vector) #최대값\n",
    "    indices = np.nonzero(vector == m)[0] #최대값을 가지는 index들\n",
    "    return pr.choice(indices)\n",
    "\n",
    "#register(id='FrozenLake-v3', entry_point='gym.envs.toy_text:FrozenLakeEnv', kwargs={'map_name':'4x4', 'is_slippery':False})\n",
    "env = gym.make('FrozenLake-v3')\n",
    "\n",
    "\n",
    "### Q-learning algorithm\n",
    "\n",
    "#Initialize table with all zeros\n",
    "Q = np.zeros([env.observation_space.n, env.action_space.n])\n",
    "\n",
    "#Set learning parameters\n",
    "num_episodes = 200\n",
    "\n",
    "#Create list to contain total rewards and steps per episode \n",
    "rList = []\n",
    "for i in range(num_episodes):\n",
    "    #Reset environment and get first new observation\n",
    "    state = env.reset()\n",
    "    rAll = 0\n",
    "    done = False\n",
    "    \n",
    "    #The Q-Table learning algorithm\n",
    "    while not done:\n",
    "        action = rargmax(Q[state,:])\n",
    "        \n",
    "        #Get new state and reward from environment\n",
    "        new_state, reward, done, _ = env.step(action)\n",
    "        \n",
    "        #Update Q-Table with new knowledge using learning rate\n",
    "        Q[state,action] = reward + np.max(Q[new_state,:])\n",
    "        \n",
    "        rAll += reward\n",
    "        state = new_state\n",
    "        \n",
    "    rList.append(rAll)\n",
    "    \n",
    "    \n",
    "print(\"Success rate :\", str(sum(rList)/num_episodes))\n",
    "print(\"Final Q-Table values\")\n",
    "print(\"LEFT DOWN RIGHT UP\")\n",
    "print(Q)\n",
    "plt.bar(range(len(rList)), rList, color='blue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## random noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success rate : 0.9615\n",
      "Final Q-Table values\n",
      "LEFT DOWN RIGHT UP\n",
      "[[0.         0.95099005 0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.96059601 0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.970299   0.        ]\n",
      " [0.         0.         0.9801     0.        ]\n",
      " [0.         0.99       0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         0.         0.        ]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAAPiUlEQVR4nO3df6xfd13H8eeLlmECA4a9kqU/aNFibNS4eTOX8EMSENpFWxVD2kgYuNCYMAMBNSUzk8y/BhET4gRrWPgRYQwUvYklBXFKYuxcB2OsG2V3ZbjWsZUxhwZlVN/+8T2Fb+/u936/3/b7/d72w/ORfHPP+ZzP/Z73/ZxzX/fcc+45N1WFJOnC97TVLkCSNBkGuiQ1wkCXpEYY6JLUCANdkhqxdrVWvG7dutq8efNqrV6SLkh33nnnN6tqbrllqxbomzdv5vDhw6u1ekm6ICX5+qBlnnKRpEYY6JLUCANdkhphoEtSIwx0SWqEgS5JjRga6EluTvJoknsGLE+S9yZZTHJ3kssnX6YkaZhRjtA/CGxfYfkOYGv32gu879zLkiSNa2igV9XngW+t0GUX8OHqOQQ8N8mlkypQkjSaSdwpuh54qG/+eNf28NKOSfbSO4pn06ZNE1j1YAmc/t8dyQ/aq86c7/fDsmy5Pi0sG2cMXDb+svNhG7ey30zr/wrN9KJoVe2vqvmqmp+bW/ZRBJKkszSJQD8BbOyb39C1SZJmaBKBvgC8vvtrlyuBJ6rqKadbJEnTNfQcepKPAS8H1iU5Dvwh8HSAqno/cAC4ClgEvgO8cVrFSpIGGxroVbVnyPIC3jyxiiRJZ8U7RSWpEQa6JDXCQJekRhjoktQIA12SGmGgS1IjDHRJaoSBLkmNMNAlqREGuiQ1wkCXpEYY6JLUCANdkhphoEtSIwx0SWqEgS5JjTDQJakRBrokNcJAl6RGGOiS1AgDXZIaYaBLUiMMdElqhIEuSY0w0CWpEQa6JDXCQJekRhjoktQIA12SGmGgS1IjDHRJaoSBLkmNGCnQk2xPcjTJYpJ9yyzflOS2JF9McneSqyZfqiRpJUMDPcka4CZgB7AN2JNk25JufwDcWlWXAbuBP5t0oZKklY1yhH4FsFhVx6rqSeAWYNeSPgU8u5t+DvDvkytRkjSKUQJ9PfBQ3/zxrq3fO4HXJTkOHAB+Z7k3SrI3yeEkh0+ePHkW5UqSBpnURdE9wAeragNwFfCRJE9576raX1XzVTU/Nzc3oVVLkmC0QD8BbOyb39C19bsGuBWgqv4F+BFg3SQKlCSNZpRAvwPYmmRLkovoXfRcWNLn34BXACT5KXqB7jkVSZqhoYFeVaeAa4GDwH30/prlSJIbkuzsur0deFOSLwEfA95QVTWtoiVJT7V2lE5VdYDexc7+tuv7pu8FXjzZ0iRJ4/BOUUlqhIEuSY0w0CWpEQa6JDXCQJekRhjoktQIA12SGmGgS1IjDHRJaoSBLkmNMNAlqREGuiQ1wkCXpEYY6JLUCANdkhphoEtSIwx0SWqEgS5JjTDQJakRBrokNcJAl6RGGOiS1AgDXZIaYaBLUiMMdElqhIEuSY0w0CWpEQa6JDXCQJekRhjoktQIA12SGmGgS1IjRgr0JNuTHE2ymGTfgD6vTXJvkiNJPjrZMiVJw6wd1iHJGuAm4JeA48AdSRaq6t6+PluBdwAvrqrHk/zYtAqWJC1vlCP0K4DFqjpWVU8CtwC7lvR5E3BTVT0OUFWPTrZMSdIwowT6euChvvnjXVu/FwEvSvLPSQ4l2T6pAiVJoxl6ymWM99kKvBzYAHw+yc9U1X/0d0qyF9gLsGnTpgmtWpIEox2hnwA29s1v6Nr6HQcWqup7VfU14Kv0Av4MVbW/quaran5ubu5sa5YkLWOUQL8D2JpkS5KLgN3AwpI+f0Pv6Jwk6+idgjk2uTIlScMMDfSqOgVcCxwE7gNuraojSW5IsrPrdhB4LMm9wG3A71XVY9MqWpL0VCOdQ6+qA8CBJW3X900X8LbuJUlaBd4pKkmNMNAlqREGuiQ1wkCXpEYY6JLUCANdkhphoEtSIwx0SWqEgS5JjTDQJakRBrokNcJAl6RGGOiS1AgDXZIaYaBLUiMMdElqhIEuSY0w0CWpEQa6JDXCQJekRhjoktQIA12SGmGgS1IjDHRJaoSBLkmNMNAlqREGuiQ1wkCXpEYY6JLUCANdkhphoEtSIwx0SWqEgS5JjRgp0JNsT3I0yWKSfSv0e02SSjI/uRIlSaMYGuhJ1gA3ATuAbcCeJNuW6Xcx8Bbg9kkXKUkabpQj9CuAxao6VlVPArcAu5bp90fAjcD/TLA+SdKIRgn09cBDffPHu7bvS3I5sLGq/m6lN0qyN8nhJIdPnjw5drGSpMHO+aJokqcB7wHePqxvVe2vqvmqmp+bmzvXVUuS+owS6CeAjX3zG7q20y4Gfhr4xyQPAlcCC14YlaTZGiXQ7wC2JtmS5CJgN7BwemFVPVFV66pqc1VtBg4BO6vq8FQqliQta2igV9Up4FrgIHAfcGtVHUlyQ5Kd0y5QkjSataN0qqoDwIElbdcP6Pvycy9LkjQu7xSVpEYY6JLUCANdkhphoEtSIwx0SWqEgS5JjTDQJakRBrokNcJAl6RGGOiS1AgDXZIaYaBLUiMMdElqhIEuSY0w0CWpEQa6JDXCQJekRhjoktQIA12SGmGgS1IjDHRJaoSBLkmNMNAlqREGuiQ1wkCXpEYY6JLUCANdkhphoEtSIwx0SWqEgS5JjTDQJakRBrokNWKkQE+yPcnRJItJ9i2z/G1J7k1yd5LPJXnB5EuVJK1kaKAnWQPcBOwAtgF7kmxb0u2LwHxV/SzwSeBdky5UkrSyUY7QrwAWq+pYVT0J3ALs6u9QVbdV1Xe62UPAhsmWKUkaZpRAXw881Dd/vGsb5Brg08stSLI3yeEkh0+ePDl6lZKkoSZ6UTTJ64B54N3LLa+q/VU1X1Xzc3Nzk1y1JP3QWztCnxPAxr75DV3bGZK8ErgO+MWq+u5kypMkjWqUI/Q7gK1JtiS5CNgNLPR3SHIZ8OfAzqp6dPJlSpKGGRroVXUKuBY4CNwH3FpVR5LckGRn1+3dwLOATyS5K8nCgLeTJE3JKKdcqKoDwIElbdf3Tb9ywnVJksbknaKS1AgDXZIaYaBLUiMMdElqhIEuSY0w0CWpEQa6JDXCQJekRhjoktQIA12SGmGgS1IjDHRJaoSBLkmNMNAlqREGuiQ1wkCXpEYY6JLUCANdkhphoEtSIwx0SWqEgS5JjTDQJakRBrokNcJAl6RGGOiS1AgDXZIaYaBLUiMMdElqhIEuSY0w0CWpEQa6JDXCQJekRhjoktSIkQI9yfYkR5MsJtm3zPJnJPl4t/z2JJsnXqkkaUVDAz3JGuAmYAewDdiTZNuSbtcAj1fVTwB/Atw46UIlSSsb5Qj9CmCxqo5V1ZPALcCuJX12AR/qpj8JvCJJJlemJGmYtSP0WQ881Dd/HPiFQX2q6lSSJ4AfBb7Z3ynJXmBvN/tfSY6eTdHAuqXvvZzlfqSs9GNmAsueUteU1zfqsnXAN08vW2lcVmHZwDEb9z2X9jnHZWfUdZ5sR4B1yeB9f5q1zGo7TnjZ0H1/6efPYtly4zWGFwxaMEqgT0xV7Qf2n+v7JDlcVfMTKGmirGt852tt1jUe6xrPtOoa5ZTLCWBj3/yGrm3ZPknWAs8BHptEgZKk0YwS6HcAW5NsSXIRsBtYWNJnAbi6m/4N4B+qqiZXpiRpmKGnXLpz4tcCB4E1wM1VdSTJDcDhqloAPgB8JMki8C16oT9N53zaZkqsa3zna23WNR7rGs9U6ooH0pLUBu8UlaRGGOiS1IgLLtCHPYZgyuvemOS2JPcmOZLkLV37O5OcSHJX97qq73Pe0dV6NMmrp1jbg0m+3K3/cNf2vCSfTXJ/9/GSrj1J3tvVdXeSy6dU00/2jcldSb6d5K2rMV5Jbk7yaJJ7+trGHp8kV3f9709y9XLrmkBd707ylW7dn0ry3K59c5L/7hu39/d9zs9323+xq/2cbuwbUNfY223S368D6vp4X00PJrmra5/leA3KhtnuY1V1wbzoXZR9AHghcBHwJWDbDNd/KXB5N30x8FV6j0N4J/C7y/Tf1tX4DGBLV/uaKdX2ILBuSdu7gH3d9D7gxm76KuDTQIArgdtntO2+Qe+miJmPF/Ay4HLgnrMdH+B5wLHu4yXd9CVTqOtVwNpu+sa+ujb391vyPv/a1Zqu9h1TqGus7TaN79fl6lqy/I+B61dhvAZlw0z3sQvtCH2UxxBMTVU9XFVf6Kb/E7iP3l2yg+wCbqmq71bV14BFel/DrPQ/kuFDwK/2tX+4eg4Bz01y6ZRreQXwQFV9fYU+Uxuvqvo8vb/AWrq+ccbn1cBnq+pbVfU48Flg+6TrqqrPVNWpbvYQvXs/Bupqe3ZVHapeKny472uZWF0rGLTdJv79ulJd3VH2a4GPrfQeUxqvQdkw033sQgv05R5DsFKgTk16T5S8DLi9a7q2+9Xp5tO/VjHbegv4TJI703vEAsDzq+rhbvobwPNXoa7TdnPmN9pqjxeMPz6rMW6/Re9I7rQtSb6Y5J+SvLRrW9/VMou6xtlusx6vlwKPVNX9fW0zH68l2TDTfexCC/TzQpJnAX8FvLWqvg28D/hx4OeAh+n92jdrL6mqy+k9FfPNSV7Wv7A7ElmVv1FN74a0ncAnuqbzYbzOsJrjM0iS64BTwF92TQ8Dm6rqMuBtwEeTPHuGJZ13222JPZx50DDz8VomG75vFvvYhRboozyGYKqSPJ3eBvvLqvprgKp6pKr+t6r+D/gLfnCaYGb1VtWJ7uOjwKe6Gh45fSql+/jorOvq7AC+UFWPdDWu+nh1xh2fmdWX5A3ALwO/2QUB3SmNx7rpO+mdn35RV0P/aZmp1HUW222W47UW+HXg4331znS8lssGZryPXWiBPspjCKamO0f3AeC+qnpPX3v/+edfA05fgV8Adqf3D0C2AFvpXYyZdF3PTHLx6Wl6F9Xu4cxHMlwN/G1fXa/vrrRfCTzR92vhNJxx5LTa49Vn3PE5CLwqySXd6YZXdW0TlWQ78PvAzqr6Tl/7XHr/n4AkL6Q3Pse62r6d5MpuH31939cyybrG3W6z/H59JfCVqvr+qZRZjtegbGDW+9i5XNldjRe9q8NfpffT9roZr/sl9H5luhu4q3tdBXwE+HLXvgBc2vc513W1HuUcr6SvUNcL6f0FwZeAI6fHhd4jjD8H3A/8PfC8rj30/mnJA13d81Mcs2fSe1Dbc/raZj5e9H6gPAx8j955yWvOZnzondNe7F5vnFJdi/TOo57ex97f9X1Nt33vAr4A/Erf+8zTC9gHgD+luwt8wnWNvd0m/f26XF1d+weB317Sd5bjNSgbZrqPeeu/JDXiQjvlIkkawECXpEYY6JLUCANdkhphoEtSIwx0SWqEgS5Jjfh/zrAeVeXlr0EAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from gym.envs.registration import register\n",
    "import random as pr\n",
    "\n",
    "#register(id='FrozenLake-v3', entry_point='gym.envs.toy_text:FrozenLakeEnv', kwargs={'map_name':'4x4', 'is_slippery':False})\n",
    "env = gym.make('FrozenLake-v3')\n",
    "\n",
    "\n",
    "### Q-learning algorithm\n",
    "\n",
    "#Initialize table with all zeros\n",
    "Q = np.zeros([env.observation_space.n, env.action_space.n])\n",
    "\n",
    "#Discount factor\n",
    "dis = 0.99\n",
    "\n",
    "#Set learning parameters\n",
    "num_episodes = 2000\n",
    "\n",
    "#Create list to contain total rewards and steps per episode \n",
    "rList = []\n",
    "for i in range(num_episodes):\n",
    "    #Reset environment and get first new observation\n",
    "    state = env.reset()\n",
    "    rAll = 0\n",
    "    done = False\n",
    "    \n",
    "    #The Q-Table learning algorithm\n",
    "    while not done:\n",
    "        #Choose an action by greedily (with noise) picking from Q table\n",
    "        action = np.argmax(Q[state,:] + np.random.randn(1,env.action_space.n)/(i+1))\n",
    "        \n",
    "        #Get new state and reward from environment\n",
    "        new_state, reward, done, _ = env.step(action)\n",
    "        \n",
    "        #Update Q-Table with new knowledge using decaying learning rate\n",
    "        Q[state,action] = reward + dis*np.max(Q[new_state,:])\n",
    "        \n",
    "        rAll += reward\n",
    "        state = new_state\n",
    "        \n",
    "    rList.append(rAll)\n",
    "    \n",
    "    \n",
    "print(\"Success rate :\", str(sum(rList)/num_episodes))\n",
    "print(\"Final Q-Table values\")\n",
    "print(\"LEFT DOWN RIGHT UP\")\n",
    "print(Q)\n",
    "plt.bar(range(len(rList)), rList, color='blue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## e-greedy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success rate : 0.8185\n",
      "Final Q-Table values\n",
      "LEFT DOWN RIGHT UP\n",
      "[[0.94148015 0.95099005 0.93206535 0.94148015]\n",
      " [0.94148015 0.         0.92274469 0.93206535]\n",
      " [0.93206535 0.         0.         0.92274469]\n",
      " [0.92274469 0.         0.         0.        ]\n",
      " [0.95099005 0.96059601 0.         0.94148015]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.96059601 0.         0.970299   0.95099005]\n",
      " [0.96059601 0.9801     0.9801     0.        ]\n",
      " [0.970299   0.99       0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.9801     0.99       0.970299  ]\n",
      " [0.9801     0.99       1.         0.9801    ]\n",
      " [0.         0.         0.         0.        ]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAAP8UlEQVR4nO3df6xkZ13H8feHXYoJFCjulTT7g110MW7U2HpTm/BDEhB2G91VMaSNhIINGxNqIKCmpKaS+lchYkKs4BoafgQoBUU3ccmCWCUxtnYLpXRblt4uxe5a2qXUokEp1a9/zFmYnc7cmdmdmdt9fL+SyT3nOc+c873Pmfncc8+5Z26qCknS2e9pa12AJGk2DHRJaoSBLkmNMNAlqREGuiQ1Yv1abXjDhg21devWtdq8JJ2Vbr/99m9V1dKwZWsW6Fu3buXQoUNrtXlJOisl+caoZZ5ykaRGGOiS1AgDXZIaYaBLUiMMdElqhIEuSY0YG+hJbkjycJK7RixPkvcmWUlyZ5ILZ1+mJGmcSY7QPwjsXGX5LmB799gLvO/My5IkTWtsoFfVF4Bvr9JlD/Dh6rkFeG6S82dVoCRpMrO4U3Qj8EDf/LGu7cHBjkn20juKZ8uWLTPY9JlJoOqHXwfbYPTywXWcnB40bNm4bQ72GVzvsLZh2xr8PkZta1xNw/4HyrDxWW2dky6bZPuTjPmw9lHLhtUy2DbJ88a9bs60zmHLVtvnw563Wi3j6jydfdxv0vfALLY3zett0rGb5Hmr9RtV6ywt9KJoVe2rquWqWl5aGvpRBJKk0zSLQD8ObO6b39S1SZIWaBaBvh94fffXLhcDj1XVk063SJLma+w59CQfB14ObEhyDPhD4OkAVfV+4ABwCbACfBd447yKlSSNNjbQq+qyMcsLePPMKpIknRbvFJWkRhjoktQIA12SGmGgS1IjDHRJaoSBLkmNMNAlqREGuiQ1wkCXpEYY6JLUCANdkhphoEtSIwx0SWqEgS5JjTDQJakRBrokNcJAl6RGGOiS1AgDXZIaYaBLUiMMdElqhIEuSY0w0CWpEQa6JDXCQJekRhjoktQIA12SGmGgS1IjDHRJaoSBLkmNMNAlqREGuiQ1YqJAT7IzyZEkK0muGrJ8S5Kbk3wpyZ1JLpl9qZKk1YwN9CTrgOuBXcAO4LIkOwa6/QFwU1VdAFwK/NmsC5UkrW6SI/SLgJWqOlpVjwM3AnsG+hTw7G76OcC/za5ESdIkJgn0jcADffPHurZ+7wRel+QYcAD4nWErSrI3yaEkh06cOHEa5UqSRpnVRdHLgA9W1SbgEuAjSZ607qraV1XLVbW8tLQ0o01LkmCyQD8ObO6b39S19bsCuAmgqv4Z+BFgwywKlCRNZpJAvw3YnmRbknPoXfTcP9DnX4FXACT5KXqB7jkVSVqgsYFeVU8AVwIHgXvo/TXL4STXJtnddXs78KYkXwY+DryhqmpeRUuSnmz9JJ2q6gC9i539bdf0Td8NvHi2pUmSpuGdopLUCANdkhphoEtSIwx0SWqEgS5JjTDQJakRBrokNcJAl6RGGOiS1AgDXZIaYaBLUiMMdElqhIEuSY0w0CWpEQa6JDXCQJekRhjoktQIA12SGmGgS1IjDHRJaoSBLkmNMNAlqREGuiQ1wkCXpEYY6JLUCANdkhphoEtSIwx0SWqEgS5JjTDQJakRBrokNcJAl6RGTBToSXYmOZJkJclVI/q8NsndSQ4n+dhsy5QkjbN+XIck64DrgV8CjgG3JdlfVXf39dkOvAN4cVU9muTH5lWwJGm4SY7QLwJWqupoVT0O3AjsGejzJuD6qnoUoKoenm2ZkqRxJgn0jcADffPHurZ+LwJelOSfktySZOesCpQkTWbsKZcp1rMdeDmwCfhCkp+pqn/v75RkL7AXYMuWLTPatCQJJjtCPw5s7pvf1LX1Owbsr6rvV9XXga/RC/hTVNW+qlququWlpaXTrVmSNMQkgX4bsD3JtiTnAJcC+wf6/DW9o3OSbKB3Cubo7MqUJI0zNtCr6gngSuAgcA9wU1UdTnJtkt1dt4PAI0nuBm4Gfq+qHplX0ZKkJ5voHHpVHQAODLRd0zddwNu6hyRpDXinqCQ1wkCXpEYY6JLUCANdkhphoEtSIwx0SWqEgS5JjTDQJakRBrokNcJAl6RGGOiS1AgDXZIaYaBLUiMMdElqhIEuSY0w0CWpEQa6JDXCQJekRhjoktQIA12SGmGgS1IjDHRJaoSBLkmNMNAlqREGuiQ1wkCXpEYY6JLUCANdkhphoEtSIwx0SWqEgS5JjTDQJakRBrokNWKiQE+yM8mRJCtJrlql32uSVJLl2ZUoSZrE2EBPsg64HtgF7AAuS7JjSL9zgbcAt866SEnSeJMcoV8ErFTV0ap6HLgR2DOk3x8B1wH/PcP6JEkTmiTQNwIP9M0f69p+IMmFwOaq+tvVVpRkb5JDSQ6dOHFi6mIlSaOd8UXRJE8D3gO8fVzfqtpXVctVtby0tHSmm5Yk9Zkk0I8Dm/vmN3VtJ50L/DTwD0nuBy4G9nthVJIWa5JAvw3YnmRbknOAS4H9JxdW1WNVtaGqtlbVVuAWYHdVHZpLxZKkocYGelU9AVwJHATuAW6qqsNJrk2ye94FSpIms36STlV1ADgw0HbNiL4vP/OyJEnT8k5RSWqEgS5JjTDQJakRBrokNcJAl6RGGOiS1AgDXZIaYaBLUiMMdElqhIEuSY0w0CWpEQa6JDXCQJekRhjoktQIA12SGmGgS1IjDHRJaoSBLkmNMNAlqREGuiQ1wkCXpEYY6JLUCANdkhphoEtSIwx0SWqEgS5JjTDQJakRBrokNcJAl6RGGOiS1AgDXZIaYaBLUiMmCvQkO5McSbKS5Kohy9+W5O4kdyb5fJIXzL5USdJqxgZ6knXA9cAuYAdwWZIdA92+BCxX1c8CnwLeNetCJUmrm+QI/SJgpaqOVtXjwI3Anv4OVXVzVX23m70F2DTbMiVJ40wS6BuBB/rmj3Vto1wBfGbYgiR7kxxKcujEiROTVylJGmumF0WTvA5YBt49bHlV7auq5apaXlpamuWmJen/vfUT9DkObO6b39S1nSLJK4GrgV+squ/NpjxJ0qQmOUK/DdieZFuSc4BLgf39HZJcAPw5sLuqHp59mZKkccYGelU9AVwJHATuAW6qqsNJrk2yu+v2buBZwCeT3JFk/4jVSZLmZJJTLlTVAeDAQNs1fdOvnHFdkqQpeaeoJDXCQJekRhjoktQIA12SGmGgS1IjDHRJaoSBLkmNMNAlqREGuiQ1wkCXpEYY6JLUCANdkhphoEtSIwx0SWqEgS5JjTDQJakRBrokNcJAl6RGGOiS1AgDXZIaYaBLUiMMdElqhIEuSY0w0CWpEQa6JDXCQJekRhjoktQIA12SGmGgS1IjDHRJaoSBLkmNMNAlqREGuiQ1YqJAT7IzyZEkK0muGrL8GUk+0S2/NcnWmVcqSVrV2EBPsg64HtgF7AAuS7JjoNsVwKNV9RPAnwDXzbpQSdLqJjlCvwhYqaqjVfU4cCOwZ6DPHuBD3fSngFckyezKlCSNs36CPhuBB/rmjwG/MKpPVT2R5DHgR4Fv9XdKshfY283+Z5Ijp1M0sGFw3afr5I+d/h8/w6ZHLR+Yf1Jdw36sTbPO1Z4/rr2/ruSHdU1b02o/miepc8yyU8Zs0u1PUtOky0Z87xuAb03z/Z3u2E25bNV9OYftndZ+PJ11rjae09QyYNX9uNp7cLV1j8uLcescNl5TeMGoBZME+sxU1T5g35muJ8mhqlqeQUkzZV3Te6rWZl3Tsa7pzKuuSU65HAc2981v6tqG9kmyHngO8MgsCpQkTWaSQL8N2J5kW5JzgEuB/QN99gOXd9O/Afx9VdXsypQkjTP2lEt3TvxK4CCwDrihqg4nuRY4VFX7gQ8AH0myAnybXujP0xmftpkT65reU7U265qOdU1nLnXFA2lJaoN3ikpSIwx0SWrEWRfo4z6GYM7b3pzk5iR3Jzmc5C1d+zuTHE9yR/e4pO857+hqPZLk1XOs7f4kX+m2f6hre16SzyW5t/t6XteeJO/t6rozyYVzqukn+8bkjiTfSfLWtRivJDckeTjJXX1tU49Pksu7/vcmuXzYtmZQ17uTfLXb9qeTPLdr35rkv/rG7f19z/n5bv+vdLWf0Y19I+qaer/N+v06oq5P9NV0f5I7uvZFjteobFjsa6yqzpoHvYuy9wEvBM4BvgzsWOD2zwcu7KbPBb5G7+MQ3gn87pD+O7oanwFs62pfN6fa7gc2DLS9C7iqm74KuK6bvgT4DBDgYuDWBe27b9K7KWLh4wW8DLgQuOt0xwd4HnC0+3peN33eHOp6FbC+m76ur66t/f0G1vMvXa3pat81h7qm2m/zeL8Oq2tg+R8D16zBeI3KhoW+xs62I/RJPoZgbqrqwar6Yjf9H8A99O6SHWUPcGNVfa+qvg6s0PseFqX/Ixk+BPxqX/uHq+cW4LlJzp9zLa8A7quqb6zSZ27jVVVfoPcXWIPbm2Z8Xg18rqq+XVWPAp8Dds66rqr6bFU90c3eQu/ej5G62p5dVbdULxU+3Pe9zKyuVYzabzN/v65WV3eU/Vrg46utY07jNSobFvoaO9sCfdjHEKwWqHOT3idKXgDc2jVd2f3qdMPJX6tYbL0FfDbJ7el9xALA86vqwW76m8Dz16Cuky7l1DfaWo8XTD8+azFuv0XvSO6kbUm+lOQfk7y0a9vY1bKIuqbZb4ser5cCD1XVvX1tCx+vgWxY6GvsbAv0p4QkzwL+EnhrVX0HeB/w48DPAQ/S+7Vv0V5SVRfS+1TMNyd5Wf/C7khkTf5GNb0b0nYDn+yangrjdYq1HJ9RklwNPAF8tGt6ENhSVRcAbwM+luTZCyzpKbffBlzGqQcNCx+vIdnwA4t4jZ1tgT7JxxDMVZKn09thH62qvwKoqoeq6n+q6n+Bv+CHpwkWVm9VHe++Pgx8uqvhoZOnUrqvDy+6rs4u4ItV9VBX45qPV2fa8VlYfUneAPwy8JtdENCd0nikm76d3vnpF3U19J+WmUtdp7HfFjle64FfBz7RV+9Cx2tYNrDg19jZFuiTfAzB3HTn6D4A3FNV7+lr7z///GvAySvw+4FL0/sHINuA7fQuxsy6rmcmOffkNL2Landx6kcyXA78TV9dr++utF8MPNb3a+E8nHLktNbj1Wfa8TkIvCrJed3phld1bTOVZCfw+8DuqvpuX/tSev+fgCQvpDc+R7vavpPk4u41+vq+72WWdU273xb5fn0l8NWq+sGplEWO16hsYNGvsTO5srsWD3pXh79G76ft1Qve9kvo/cp0J3BH97gE+Ajwla59P3B+33Ou7mo9whleSV+lrhfS+wuCLwOHT44LvY8w/jxwL/B3wPO69tD7pyX3dXUvz3HMnknvg9qe09e28PGi9wPlQeD79M5LXnE640PvnPZK93jjnOpaoXce9eRr7P1d39d0+/cO4IvAr/StZ5lewN4H/CndXeAzrmvq/Tbr9+uwurr2DwK/PdB3keM1KhsW+hrz1n9JasTZdspFkjSCgS5JjTDQJakRBrokNcJAl6RGGOiS1AgDXZIa8X9OuzxzE/dQoAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from gym.envs.registration import register\n",
    "import random as pr\n",
    "\n",
    "#register(id='FrozenLake-v3', entry_point='gym.envs.toy_text:FrozenLakeEnv', kwargs={'map_name':'4x4', 'is_slippery':False})\n",
    "env = gym.make('FrozenLake-v3')\n",
    "\n",
    "\n",
    "### Q-learning algorithm\n",
    "\n",
    "#Initialize table with all zeros\n",
    "Q = np.zeros([env.observation_space.n, env.action_space.n])\n",
    "\n",
    "#Discount factor\n",
    "dis = 0.99\n",
    "\n",
    "#Set learning parameters\n",
    "num_episodes = 2000\n",
    "\n",
    "#Create list to contain total rewards and steps per episode \n",
    "rList = []\n",
    "for i in range(num_episodes):\n",
    "    #Reset environment and get first new observation\n",
    "    state = env.reset()\n",
    "    rAll = 0\n",
    "    done = False\n",
    "    \n",
    "    e = 1.0 / ((i/100)+1)\n",
    "    \n",
    "    #The Q-Table learning algorithm\n",
    "    while not done:\n",
    "        #Choose an action by e greedy\n",
    "        if np.random.rand(1) < e:\n",
    "            action = env.action_space.sample()\n",
    "        else:\n",
    "            action = np.argmax(Q[state,:])\n",
    "            \n",
    "        #Get new state and reward from environment\n",
    "        new_state, reward, done, _ = env.step(action)\n",
    "        \n",
    "        #Update Q-Table with new knowledge using decaying learning rate\n",
    "        Q[state,action] = reward + dis*np.max(Q[new_state,:])\n",
    "        \n",
    "        rAll += reward\n",
    "        state = new_state\n",
    "        \n",
    "    rList.append(rAll)\n",
    "    \n",
    "    \n",
    "print(\"Success rate :\", str(sum(rList)/num_episodes))\n",
    "print(\"Final Q-Table values\")\n",
    "print(\"LEFT DOWN RIGHT UP\")\n",
    "print(Q)\n",
    "plt.bar(range(len(rList)), rList, color='blue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success rate : 0.016\n",
      "Final Q-Table values\n",
      "LEFT DOWN RIGHT UP\n",
      "[[0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.95099005 0.        ]\n",
      " [0.         0.9801     0.         0.        ]\n",
      " [0.         0.         0.         0.        ]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from gym.envs.registration import register\n",
    "import random as pr\n",
    "\n",
    "#register(id='FrozenLake-v3', entry_point='gym.envs.toy_text:FrozenLakeEnv', kwargs={'map_name':'4x4', 'is_slippery':False})\n",
    "env = gym.make('FrozenLake-v0')\n",
    "\n",
    "\n",
    "### Q-learning algorithm\n",
    "\n",
    "#Initialize table with all zeros\n",
    "Q = np.zeros([env.observation_space.n, env.action_space.n])\n",
    "\n",
    "#Discount factor\n",
    "dis = 0.99\n",
    "num_episodes = 2000\n",
    "\n",
    "#Create list to contain total rewards and steps per episode \n",
    "rList = []\n",
    "for i in range(num_episodes):\n",
    "    #Reset environment and get first new observation\n",
    "    state = env.reset()\n",
    "    rAll = 0\n",
    "    done = False\n",
    "    \n",
    "    e = 1.0 / ((i/100)+1)\n",
    "    \n",
    "    #The Q-Table learning algorithm\n",
    "    while not done:\n",
    "        #Choose an action by greedily (with noise) picking from Q table\n",
    "        action = np.argmax(Q[state,:] + np.random.randn(1,env.action_space.n)/(i+1))\n",
    "        \n",
    "        #Get new state and reward from environment\n",
    "        new_state, reward, done, _ = env.step(action)\n",
    "        \n",
    "        #Update Q-Table with new knowledge using decaying learning rate\n",
    "        Q[state,action] = reward + dis*np.max(Q[new_state,:])\n",
    "        \n",
    "        rAll += reward\n",
    "        state = new_state\n",
    "        \n",
    "    rList.append(rAll)\n",
    "    \n",
    "    \n",
    "print(\"Success rate :\", str(sum(rList)/num_episodes))\n",
    "print(\"Final Q-Table values\")\n",
    "print(\"LEFT DOWN RIGHT UP\")\n",
    "print(Q)\n",
    "plt.bar(range(len(rList)), rList, color='blue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success rate : 0.6655\n",
      "Final Q-Table values\n",
      "LEFT DOWN RIGHT UP\n",
      "[[5.84840624e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 7.02858934e-01]\n",
      " [5.99110549e-01 6.12802291e-04 0.00000000e+00 0.00000000e+00]\n",
      " [5.15673128e-04 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [6.93439226e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [4.47212107e-01 5.16678483e-05 2.71325548e-04 1.95199739e-05]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 7.18886686e-01]\n",
      " [0.00000000e+00 8.55707910e-01 0.00000000e+00 9.89855029e-04]\n",
      " [9.26191747e-01 2.02268583e-04 4.10294100e-04 1.84503512e-03]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [2.85643656e-03 0.00000000e+00 9.26810817e-01 5.51037401e-03]\n",
      " [0.00000000e+00 9.42664147e-01 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from gym.envs.registration import register\n",
    "import random as pr\n",
    "\n",
    "#register(id='FrozenLake-v3', entry_point='gym.envs.toy_text:FrozenLakeEnv', kwargs={'map_name':'4x4', 'is_slippery':False})\n",
    "env = gym.make('FrozenLake-v0')\n",
    "\n",
    "\n",
    "### Q-learning algorithm\n",
    "\n",
    "#Initialize table with all zeros\n",
    "Q = np.zeros([env.observation_space.n, env.action_space.n])\n",
    "\n",
    "#Discount factor\n",
    "learning_rate = 0.85 #크면 빨리 학습\n",
    "dis = 0.99\n",
    "num_episodes = 2000\n",
    "\n",
    "#Create list to contain total rewards and steps per episode \n",
    "rList = []\n",
    "for i in range(num_episodes):\n",
    "    #Reset environment and get first new observation\n",
    "    state = env.reset()\n",
    "    rAll = 0\n",
    "    done = False\n",
    "    \n",
    "    e = 1.0 / ((i/100)+1)\n",
    "    \n",
    "    #The Q-Table learning algorithm\n",
    "    while not done:\n",
    "        #Choose an action by greedily (with noise) picking from Q table\n",
    "        action = np.argmax(Q[state,:] + np.random.randn(1,env.action_space.n)/(i+1))\n",
    "            \n",
    "        #Get new state and reward from environment\n",
    "        new_state, reward, done, _ = env.step(action)\n",
    "        \n",
    "        #Update Q-Table with new knowledge using learning rate\n",
    "        #내 지식과 새로운 지식을 적절히 분배해서 받아들임\n",
    "        Q[state,action] = (1-learning_rate)*Q[state,action] + learning_rate*(reward + dis*np.max(Q[new_state,:]))\n",
    "        \n",
    "        rAll += reward\n",
    "        state = new_state\n",
    "        \n",
    "    rList.append(rAll)\n",
    "    \n",
    "    \n",
    "print(\"Success rate :\", str(sum(rList)/num_episodes))\n",
    "print(\"Final Q-Table values\")\n",
    "print(\"LEFT DOWN RIGHT UP\")\n",
    "print(Q)\n",
    "plt.bar(range(len(rList)), rList, color='blue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(np.identity(16)[0:1]) #np.identity: 단위행렬\n",
    "print(np.eye(16)[10:11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(x):\n",
    "    return np.identity(16)[x:x+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'placeholder'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-4171f152bc77>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# These lines establish the feed-forward part of the network used to choose actions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#state input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_uniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#weight Variable: 학습할수 있는 변수\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'placeholder'"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "env = gym.make('FrozenLake-v0')\n",
    "\n",
    "# Input and output size based on the Env\n",
    "input_size = env.observation_space.n\n",
    "output_size = env.action_space.n\n",
    "learning_rate = 0.1\n",
    "\n",
    "# These lines establish the feed-forward part of the network used to choose actions\n",
    "X = tf.placeholder(shape=[1,input_size], dtype=tf.float32) #state input\n",
    "W = tf.Variable(tf.random_uniform([input_size,output_size], 0, 0.01)) #weight Variable: 학습할수 있는 변수\n",
    "\n",
    "Qpred = tf.matmul(X,W) #Out Q prediction\n",
    "Y = tf.placeholder(shape=[1,output_size], dtype=tf.float32) #Y label\n",
    "\n",
    "loss = tf.reduce_sum(tf.square(Y-Qpred))\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(loss)\n",
    "\n",
    "# Set Q-learning related parameters\n",
    "dis = .99\n",
    "num_episodes = 2000\n",
    "\n",
    "# Create lists to contain total rewards and steps and steps per episode\n",
    "rList = []\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for i in range(num_episodes):\n",
    "        # Reset environment and get first new observation\n",
    "        s = env.reset()\n",
    "        e = 1. / ((i/50) + 10)\n",
    "        rAll = 0\n",
    "        done = False\n",
    "        local_loss = []\n",
    "        \n",
    "        # The Q-Network training\n",
    "        while not done:\n",
    "            # Choose an action by greedily (with e chance of random action) from the Q-network\n",
    "            Qs = sess.run(Qpred,feed_dict={X: one_hot(s)})\n",
    "            if np.random.rand(1) < e:\n",
    "                a = env.action_space.sample()\n",
    "            else:\n",
    "                a = np.argmax(Qs)\n",
    "                \n",
    "            # Get new state and reward from environment\n",
    "            s1, reward, done, _ = env.step(a)\n",
    "            if done:\n",
    "                # Update Q, and no Qs+1, since it's a terminal state\n",
    "                Qs[0,a] = reward\n",
    "            else:\n",
    "                # Obtain the Q_s1 values by feeding the new state through our network\n",
    "                Qs1 = sess.run(Qpred,feed_dict={X: one_hot(s1)})\n",
    "                # Update Q\n",
    "                Qs[0,a] = reward + dis*np.max(Qs1)\n",
    "                \n",
    "            # Train our network using target (Y) and predicted Q (Qpred) values\n",
    "            sess.run(train, feed_dict={X: one_hot(s), Y:Qs})\n",
    "            \n",
    "            rAll += reward\n",
    "            s = s1\n",
    "            \n",
    "        rList.append(rAll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Keras requires TensorFlow 2.2 or higher. Install TensorFlow via `pip install tensorflow`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/envs/gym/lib/python3.7/site-packages/keras/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomRotation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.keras.layers.experimental.preprocessing'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-88d96843a926>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/gym/lib/python3.7/site-packages/keras/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     raise ImportError(\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0;34m'Keras requires TensorFlow 2.2 or higher. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         'Install TensorFlow via `pip install tensorflow`')\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: Keras requires TensorFlow 2.2 or higher. Install TensorFlow via `pip install tensorflow`"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import models, layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(128, activation='relu', input_shape=(1,input_size)))\n",
    "model.add(layers.Dense(output_size))\n",
    "model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
    "\n",
    "history = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.8.3\n"
     ]
    }
   ],
   "source": [
    "!python -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gym",
   "language": "python",
   "name": "gym"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

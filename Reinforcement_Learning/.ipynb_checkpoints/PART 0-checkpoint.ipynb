{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHAPTER 01 소개"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 강화학습\n",
    "\n",
    "- 강화학습은 비지도학습과는 다르다. 비지도학습은 데이터의 집합 안에서 숨겨진 구조를 찾지만 강화학습은 보상을 최대로 만들기 위해 노력할 뿐, 숨겨진 구조를 찾으려고 하지는 않는다.\n",
    "- 강화학습은 '탐험'과 '활용' 사이를 적절히 절충할 줄 알아야 한다. 보상을 얻기 위해 이미 경함한 행동들을 '활용(exploitation)'해야 하지만, 미래에 더 좋은 행동을 선택하기 위한 '탐험(exploration)'도 해야 한다.\n",
    "- 강화학습은 상호작용을 하는 완전하고 목표 지향적인 학습자를 처음부터 고려한 상태로 시작한다. 모든 강화학습 학습자는 '분명한 목표'가 있고, 주변 환경의 여러 측면을 감지할 수 있으며, 그 환경에 영향을 주기 위한 행동을 선택할 수 있다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 강화학습의 구성 요소\n",
    "\n",
    "***정책(policy), 보상 신호(reward signal), 가치 함수(value function)***, 주변 환경에 대한 모델(model)\n",
    "\n",
    "- 정책     : 학습자가 인지한 주변 환경의 상태에 대해 학습자가 취해야 할 행동을 정의 \n",
    "- 보상 신호 : 강화학습이 성취해야 할 목표를 정의\n",
    "- 가치 함수 : 장기적인 관점에서 무엇이 좋은 것인가를 알려줌 (특정 상태의 가치는 그 상태의 시작점에서부터 일정 시간 동안 학습자가 기대할 수 있는 보상의 총량)\n",
    "\n",
    "    => 보상이 최대인 행동보다는 가치가 최대인 행동을 선택해야 장기적으로 최대한 많은 보상을 얻을 수 있지만 가치 판단은 매우 어려운 일이다\n",
    "\n",
    "- 모델     : 환경의 변화를 모사 (환경이 어떻게 변화해 갈지를 추정할 수 있게 해줌)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 한계와 범위\n",
    "\n",
    "**상태(state)** : 특정 시각에 환경이 어떤 모습을 하고 있는지에 대한 정보를 학습자에게 전달하는 신호"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 확장된 예제: 틱택토\n",
    "\n",
    "- 진화적 방법은 정책을 평가하기 위해 정책을 고정한 채로 상대방과 많은 게임을 시도하거나 상대방의 모델을 이용하여 많은 게임을 시뮬레이션해 본다. 승리의 빈도수는 그 정책으로 승리할 확률에 대한 unbiased 추정값을 의미하며, 다음 정책 선택의 지침이 된다. 하지만 모든 정책의 수정은 많은 게임을 수행한 후에야 이루어지고 오로지 게임의 최종 결과만을 사용하게 된다. 즉, 게임 도중에 무슨 일이 일어나는지는 무시된다. => 게임 참여자가 승리하면 게임 참여자가 게임 도중 취했던 모든 행동이 신뢰를 받으며, 어떤 특정 움직임이 승리에 얼마나 기여했는지는 무시된다.\n",
    "- 가치 함수를 이용하는 방법은 개별적인 상태들을 평가하는 것을 허용하기 때문에 가치 함수를 학습하면 게임 도중에 발생한 정보를 활용할 수 있다는 이점이 있다.\n",
    "\n",
    "- 강화학습은 상태들의 집합이 매우 큰, 심지어 무한한 경우에도 적용될 수 있다. 과거의 경험을 적절히 일반화할 수 있는 경우, 새로운 상태를 접했을 때 이전에 경험했던 유사한 상태로부터 저장한 정보를 기반으로 인공 신경망을 통해 행동을 결정한다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
